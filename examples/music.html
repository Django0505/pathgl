<!DOCTYPE html>
<head>
	<meta charset="utf-8">
  <meta name="viewport"
	      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<title>WebGL Library for Data Visualization and Simulation - PathGL</title>
	
	<script src="/lib/d3.js"></script>
	<script src="/lib/topojson.v1.min.js"></script>
	<script src="/lib/projection.js"></script>
	<script src="/lib/tip.js"></script>
	<script src="../heatmap.js"></script>
		
	<script src="/dist/pathgl.js"></script>
  <link rel="stylesheet" href="/lib/adnan.css">
</head>

<body class="music examples">
  <div class="nav">
    <a href="http://github.com/adnan-wahab/pathgl">Github Repo</a>
    <a href="/dist/pathgl.zip">Download</a>

		<h3>Examples</h3>
		<ul class="examples">
			<li class="mobile-only"><a href="/examples/swarm.html">200k Circles</a>
			<li class="desktop-only"><a href="/examples/physics.html">Particle Simulation</a>
      <li><a href="/examples/map.html">Map of History</a>
      <li><a href="/examples/music.html">Music Visualizer</a>
    </ul>
		
		<h3>Documentation</h3>
		<ul class="docs">
			<li><a href="/documentation/start.html">Getting Started</a>
			<li><a href="/documentation/api.html">API Reference</a>
      <li><a href="/documentation/webgl.html">The Graphics Pipeline</a>
			<li><a href="/documentation/svg.html">SVG Differences</a>
			<li><a href="/documentation/gpgpu.html">GPGPU</a>
		</ul>
		<div class="mode">
			<h3>Rendering Mode</h3>
			<label for="svg">SVG<input type="radio" name="mode" id="svg"></label>
			<label for="webgl">WebGL<input type="radio" name="mode" checked="1" id="webgl"></label>
			<img class="t" src="data/test.png">
			<img class="l" src="data/leaves.jpg">
		</div>
	</div>
	<div class="right" id="scroll">
		<div class="blurb"><!--blurb--></div>
		<canvas width="960" height="500"></canvas>
		<svg></svg>
		<script>
d3.select('.blurb')
.append('a')
.attr('href', '#')
.text('click to play Overture by Beats Antique')
.on('click', play)

var size = { width: 960, height: 500 }

var Audio = window.AudioContext || window.webkitAudioContext
  , numLines = 2e3
  , midX = size.width / 2
  , midY = size.height / 2
  , analyzer
  , promise

var audio = d3.select('.right').append('audio')
            .attr('src', 'data/overture.mp3')
            .attr('preload', 'auto')
            .attr('loop', true)

var node = audio.on('loadeddata', function () { promise = true}).node()

function play () {
  var s = d3.select('canvas')

  var scale = Math.PI * 2 / numLines
  var texture

  promise ? initAudio.call(audio.node()) : audio.on('loadeddata', initAudio)

  var lines = s.selectAll('line').data(d3.range(numLines).map(function () { return {a: 0}}))
              .enter()
              .append('line')
              .attr({
                x1: midX
              , y1: midY
              , stroke: function () { return "hsl(" + Math.random() * 360 + ",100%, 50%)" }
              , x2: function (d, i) { return Math.cos(i * 2) * 300 }
              , y2: function (d, i) { return Math.sin(i * 2) * 300 }
              })

  d3.timer(function () {
    if (! analyzer) return

    freqData = new Uint8Array(analyzer.fftSize)
    //pathgl.texture(freqData)
    //timeData = new Uint8Array(analyzer.fftSize)

    //analyzer.getByteTimeDomainData(timeData)
    analyzer.getByteFrequencyData(freqData)
    var dMax = 0
    lines.each(function (d, i) {
      var freq  = freqData[i % 1024] * 3
      if(dMax < (d.diff = d.v - freq)) dMax = d.diff
      d.v = freq
      d.a = freq + d.diff
    })
    .attr('stroke', function (d, i) { return  i % 2 ? 'pink':'red'})
//"hsl(" + Math.abs(d.diff / dMax * 10 + 240) + ",100%, 50%)"
    .attr('x2', function (d, i) { return midX + (Math.cos(i) * d.a) })
    .attr('y2', function (d, i) { return midY + (Math.sin(i) * d.a)})
    d3.select('canvas').node().gl.lineWidth(2)
  })
  d3.select('.play').on('click', null)
}


function sort (a) {
  return [].sort.call(a, function (a, b) {
           return b - a
         })
}

function initAudio() {
  var audioContext = new Audio();
  window.analyzer = audioContext.createAnalyser();
  var source = audioContext.createMediaElementSource(this);
  source.connect(analyzer);
  analyzer.connect(audioContext.destination);
  this.play()
  this.currentTime = 83
  this.volume = .1
  this.playbackRate = 1
}

function initDnD (arrayBuffer) {
  window.audioCtx = new Audio()
  window.analyser = audioCtx.createAnalyser()

  if (window.source)
    source.noteOff(0)

  if (window.source)
    audio.stop()
  audioCtx.decodeAudioData(arrayBuffer, function(buffer) {

    window.source = audioCtx.createBufferSource()
    source.buffer = buffer

    source.connect(analyser)

    analyser.connect(audioCtx.destination)

    source.start(0)
    analyzer = analyser
  })
}

</script><p>A waveform visualization of a song. 
</p><code>d3.select('.blurb')
.append('a')
.attr('href', '#')
.text('click to play Overture by Beats Antique')
.on('click', play)

var size = { width: 960, height: 500 }

var Audio = window.AudioContext || window.webkitAudioContext
  , numLines = 2e3
  , midX = size.width / 2
  , midY = size.height / 2
  , analyzer
  , promise

var audio = d3.select('.right').append('audio')
            .attr('src', 'data/overture.mp3')
            .attr('preload', 'auto')
            .attr('loop', true)

var node = audio.on('loadeddata', function () { promise = true}).node()

function play () {
  var s = d3.select('canvas')

  var scale = Math.PI * 2 / numLines
  var texture

  promise ? initAudio.call(audio.node()) : audio.on('loadeddata', initAudio)

  var lines = s.selectAll('line').data(d3.range(numLines).map(function () { return {a: 0}}))
              .enter()
              .append('line')
              .attr({
                x1: midX
              , y1: midY
              , stroke: function () { return "hsl(" + Math.random() * 360 + ",100%, 50%)" }
              , x2: function (d, i) { return Math.cos(i * 2) * 300 }
              , y2: function (d, i) { return Math.sin(i * 2) * 300 }
              })

  d3.timer(function () {
    if (! analyzer) return

    freqData = new Uint8Array(analyzer.fftSize)
    //pathgl.texture(freqData)
    //timeData = new Uint8Array(analyzer.fftSize)

    //analyzer.getByteTimeDomainData(timeData)
    analyzer.getByteFrequencyData(freqData)
    var dMax = 0
    lines.each(function (d, i) {
      var freq  = freqData[i % 1024] * 3
      if(dMax < (d.diff = d.v - freq)) dMax = d.diff
      d.v = freq
      d.a = freq + d.diff
    })
    .attr('stroke', function (d, i) { return  i % 2 ? 'pink':'red'})
//"hsl(" + Math.abs(d.diff / dMax * 10 + 240) + ",100%, 50%)"
    .attr('x2', function (d, i) { return midX + (Math.cos(i) * d.a) })
    .attr('y2', function (d, i) { return midY + (Math.sin(i) * d.a)})
    d3.select('canvas').node().gl.lineWidth(2)
  })
  d3.select('.play').on('click', null)
}


function sort (a) {
  return [].sort.call(a, function (a, b) {
           return b - a
         })
}

function initAudio() {
  var audioContext = new Audio();
  window.analyzer = audioContext.createAnalyser();
  var source = audioContext.createMediaElementSource(this);
  source.connect(analyzer);
  analyzer.connect(audioContext.destination);
  this.play()
  this.currentTime = 83
  this.volume = .1
  this.playbackRate = 1
}

function initDnD (arrayBuffer) {
  window.audioCtx = new Audio()
  window.analyser = audioCtx.createAnalyser()

  if (window.source)
    source.noteOff(0)

  if (window.source)
    audio.stop()
  audioCtx.decodeAudioData(arrayBuffer, function(buffer) {

    window.source = audioCtx.createBufferSource()
    source.buffer = buffer

    source.connect(analyser)

    analyser.connect(audioCtx.destination)

    source.start(0)
    analyzer = analyser
  })
}
</code>
  </div>
</body>